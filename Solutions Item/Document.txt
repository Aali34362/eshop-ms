Domain Analysis of Catalog Microservice:

1. Domain Models
	Primary domain model is 'Product', associated with 'Category'
	Consider Domain  event for price changes, leading to integration events.

2. Application Use Cases
	Main use case are Listing Products and Categories, able to search products.
	CRUD Operations:
		Listing Products and Categories
		Get Product with Product id
		Get Products with category
		Create new Product
		Update Product
		Delete Product
	Along with this design our APIs according to REST perspective.

3. Rest Api Endpoints

4. Underlying Data Structures
	Document Database with Catalog JSON data.
	2 options : MongoDB No-Sql database, POSTgre Sql DB JSOn Columns. Chosen Postgre Sql with the Marten library.
	Marten is powerful library that transforms PostgreSql into .Net Transactional Document DB.
	PostgreSql's JSON column features, allowing us to store and query our data as JSON documents.
	Combines the flexibility of a document database with the reliability of relational PostgreSql database.
	----------------------------------------------------------------------------------------------------------------------------
	Technical Analysis of Catalog MicroServices :

	1. Application Architecture Style
		Vertical Slice Architecture
			Organizes our code into feature folders, each feature encapsulated in a single .cs file

	2. Patterns & Principles
		CQRS Pattern : Command Query Responsiblility Segregation divides operations into commands(write) and queries(read).
		Mediator Pattern : Facilitates object interact through a 'mediator' reducing direct dependencies and simplifying communications.
		DI in ASP.NET Core : Dependency Injection is a core feature, allowing us to inject dependencies.
		Minimal APIs and Routing in ASP.NET 8 : ASP.NET 8's Minimal APIs simplify endpoint definitions, providing light weight syntax for routing and handling HTTP requests.
		ORM Pattern : Object-Relational Mapping abstracts database interactions, work with database objects using high-level codes.


	3. Libraries Nuget Packages
		MediatR for CQRS : MediatR library simplifies the implementation of CQRS pattern.
			So Mediator Library simplifies the implementation of the Six design patterns by acting as an in-process 
			messaging mechanism, helping to send commands and queries to their respective handlers.
		Carter for API Endpoints : Routing and handling the HTTP requests, easier to define API endpoints with clean and concise code.
			Carter offers a lightweight library for routing and handling HTTP requests, making it easier to define API endpoints with clean and concise code.
		Marten for PostGreSql Interaction : USe PostgreSql as a Document DB. It leverages PostgreSQ:'s JSOn capabilities for storing, querying and managing documents.
		Mapster for Object Mapping : Mapster is a fast, configurable object mapper that simplifies the task of mapping objects.
		FluentValidation for Input Validation : For building strongly-typed validation rules, ensure inputs are correct before processed.

	4. Project Folder Structure
		The project is organized into Model, Features, Data and Abstractions.
		Features like CreateProduct and GetProduct have dedicated handlers and endpoint definitions.
		Feature folder will be Products.
		Data folder and Context objects manages database interactions.
	------------------------------------------------------------------------------------

	Vertical Slice Architecture:
		This architecture against to traditional layered/onion/clean architetured approaches.
		Aims to organize code around specific features or use cases, rather than technica concers.
		Feature is implemented across all layers of the software from user interface to the db.
		Oftern used in the development of complex feature rich apps.
		Divide application into distinct feature or functionalities, each of which cuts through all the layers of the application.
		Contrast to traditional n-tier or layered architecture where the application is divided horizontally.


		----------------------------------------
		CQRS - Command Query Responsibility Segregation
			CQRS design pattern in order to avoid complex queries to get rid of inefficient joins.
			Separates read and write operations with separating db.
			Commands: changing the state of data into application.
			Queries : handling complex join operations and returning a result and dont change the state of data into application.
			Large-scaled microservices architectures needs to manage high-volume data requirements.
			Single db for services can cause bottlenecks.
			Use both CQRS and Event Sourcing patterns to improve application performance.

			Logical and Physical Implementation of CQRS
				Logical : splitting Operations, Not DB. Separate the read and write opertations at the code level not on db
				Even though the same db is used the paths for reading and writing data are distinct.

				Physical : Separate DB, Splitting the read and write opertations not just code but phyiscally using separate DB.
				Introduces data consistency and synchronizations problems.

				IRequest : interfaces is used to define a request, which can be either a command or query.
				The return type of the request can be specified as a generic parameter

				Handler : inherits from IRequestHandler<Trequest,TReesponse>, where TRequest is the type of the command or query, and TResponse is the return type.

				TO make the distinction between commands and queries clearer, you can define two custom interface : ICommand and IQuery.
					public interface ICOmmand<TResult>  : IRequest<TResult>{}
					public interface IQuery<TResult>  : IRequest<TResult>{}

				Mediator pattern useful in complex or enterprise level applications where request processing often involves more than just business logic
				Handling a request require additional steps like logging, validaton, auditing, and applying security checks. These are known as cross-cutting cincerns.
				MediatR provides a mediator pipeline where these cross-cutting concerns can be inserted transparently.
				Pipeline coordinates the request handling, ensuring that all necessary steps are executed in the right order.
				In MediatR, pipeline behaviors are used to implement cross-cutting concerns.
				Wrap around the request handling, allowing you to execute logic before and after the actual handler is called.



Carter Library for Minimal Api :
With Asp.net core 8, Minimal Apis have become a popular way to build lightweight and performant microservices and web apis.
Carter is library that extends the capabilities of Asp.Net Core Minimal APis.
Provides a more structured way to organize our endpoints and simplifies the creation of HTTP reques handlers.
Carter is framework that is thin layer of extension methods and functionality over Asp.net core.
Carter, expecially beneficial in minimal APIs, simplify the development of minimal API endpoints.


---------------------
What is Backing Services for Cloud-Native Microservices
they are the external components that mcroservices depend on for their operation
Provide suppoty for various functionalities such as data storage, messaging, caching, and authentication.
BS like DB, Messaging systems. and caching services ae treated as attached resources
BS are external to microservice and can be swapped or replaced without changing the microservices core logic
Decoupled from the microservices themselves, promoting flexibility, scalability, and easier maintenance

	

Underlying Data Structures of Catalog Microservice
Marten is an ORM(Object-Relational Mapper) that leverages Postgresql's Json capabilites.
Marten is powerful library that transforms Postgrsql into a .net transactional Document DB.
PostGreSql's Json column features, allowing us to store and query our data as JSON documents.
Combines the flexibility of a document database with the reliability of relational PostgreSql database.
Catalog service use Marten for PostgreSql Interaction as a Document DB.


Opening Sessions in Marten as Document DB :
Martin's session is an interaction pattern for working with the documents stored in PostgreSQL database.
You can see the image on the slide.
I document store is the root of the Martin usage, but most of the Martin usage in the code will start
with one of these session types that can be created from an I document store.
So under the I document store there are different flavors of session and the root store.
So these are the query sessions that optimize for read only scenarios and document sessions that optimize
for the read and write scenarios.
So let me explain one by one.
The first one is query sessions.
These sessions is best used for querying documents without any need for the tracking or saving changes.
So under the document session for read and write operation, we can also use different type of the document sessions.
Let me start the first one which is the identity map documentation.
Martin's I document session implement the identity map pattern that seeks to cache documents loaded by ID.
This behavior can be very valuable, for example, in handling the web requests or service bus messages.
When many different objects or functions may need to access the same logical document.
The second type is lightweight document session.
It is suitable for small transactions with a mix of the read and write operations.
For operations that involve updates, inserts or deletes, we use a lightweight sessions.
It is still transactional but doesn't track the changes to the loaded document.
And the last one is dirty checking documentation.
This is the dirty checking document session in this case, and I document station opened with a dirty checking enabled.
The session will try to detect the changes to any of the documents loaded by that session.
The dirty checking is done by keeping the original Json fetched from the PostgreSQL, and using the Newtonsoft.json library that makes a node by node.
Comparison of the Json representation of the document at the time that I document session is called, so you can find the image.
How we can create these kind of sessions from the Martin Document DB.
And here you can see that we can use a document store and dot notation to create query session.
Here you can see the query session and we can create lightweight sessions, identity sessions, dirty tricks sessions and so on.
These provide to create sessions using the document store.
And here you can see the operations to perform read write operations or enable to identity map and dirty checking functions.
So what is the best practice?
Best practice is understanding and choosing the right type of the session in Martin, which is crucial
for effective data handling in your applications.
Always aim to use the lightest session that meets your needs and ensure proper disposal of the sessions
in order to maintain the performance.
So we will use mostly lightweight session which is optimized for reading and writing operations.


--------------------------------------
MediatR Pipeline Behaviours
MediatR powerful features is 'Pipeline Behaviors' allows to additional logic
into the ewquest handling process: validation, logging, exception handling and performance tracking.
Pipeline Behaviors act as middleware in the MediatR library, wrap around the request handlng process,
enabling to implement cross-cutting concerns.
A class that implements IPipelineBehavior<TRequest,TResponse>.
Handle method where you can execute code before and after the next delegate is invoked.

Fluent Validation is a .Net library for building strongly-typed validation rules
Intefrate Fluent Validation with MediatR to validate requests before they reach the actual handler within a pipeline behavior.
Fluent Validation define validation rules in separate classes, using a fluent interface to specify conditions that each property of your models must satisfy.
Combining MediatR with Fluent Validation centralized our cross-cutting concerns like validation making our code cleaner and more maintainable



IPipelineBehavior<TRequest, TResponse> is an interface in the MediatR library for .NET, 
which is used to define behaviors that can be applied to a request pipeline. 
MediatR is a popular library that facilitates the implementation of 
the mediator pattern in .NET applications. 
This pattern helps in decoupling the request/command handling logic 
from other aspects of the system, such as logging, validation, and exception handling.

Key Functions of IPipelineBehavior<TRequest, TResponse>
Pipeline Customization: 
Allows you to add custom processing logic to the request/response pipeline. 
This is useful for cross-cutting concerns like logging, caching, validation, and authorization.

Centralized Request Handling: 
By implementing IPipelineBehavior, you can manage aspects of the request 
processing in a centralized manner, making the code cleaner and more maintainable.

Pre-Processing and Post-Processing: 
You can perform actions before and after the request handler is invoked. 
For instance, you might want to log the request details before handling it and log the response details afterward.

Components

    TRequest: The type of the request.
    TResponse: The type of the response.
    RequestHandlerDelegate<TResponse>: A delegate representing the next handler in the pipeline. Calling next() moves the request to the next handler or behavior in the pipeline.

Use Cases

    Logging: Log the details of incoming requests and outgoing responses.
    Validation: Validate the request before it reaches the main handler.
    Caching: Implement caching mechanisms to avoid redundant processing.
    Authorization: Check if the user is authorized to make the request.
    Exception Handling: Catch and handle exceptions that might be thrown during the request processing.

IPipelineBehavior<TRequest, TResponse> is a powerful feature in MediatR that allows 
you to add cross-cutting concerns to your request processing pipeline. 
This can greatly enhance the modularity and maintainability of your application by centralizing common functionalities like logging, validation


------------------------------------------------

Seeding CatalogDB with Marten Initial Baseline Data
Seeding is essential for initializing the database with baseline data.
Marten provides a feature called IInitialData for this purpose.
Implement the IInitialData interface to seed our CatalogDb with predefined products.
This interfaces allows Marten to automatically populate the db when its first initialized


InitializeWith()

The InitializeWith() method is used to seed the database with initial data 
or perform some setup logic when Marten initializes. 
This is particularly useful for scenarios where you need to ensure 
certain data is available in the database before your application starts serving requests.

For example, you might want to pre-load reference data, create specific documents, or ensure certain indexes exist.


UseLightweightSessions()

The UseLightweightSessions() method configures Marten to use lightweight sessions by default. 
In Marten, there are different types of sessions you can use depending on your requirements:

Lightweight Sessions: 
These are optimized for read-heavy workloads and do not track changes to documents automatically. 
They are suitable for scenarios where you primarily perform read operations or where you manage document updates explicitly.

Dirty Tracking Sessions: 
These sessions automatically track changes to documents and are more suitable for write-heavy 
operations where you want Marten to manage changes to your documents.

Query-only Sessions: 
These sessions are read-only and do not allow any updates or changes to documents.

Using UseLightweightSessions() ensures that the sessions created by default are lightweight, 
making them suitable for applications where read performance is critical and you manage updates explicitly.

-----------------------------------------------

Health Checks
Health checks in Asp.Net Core provide a way to monitor the status of your application and its dependencies
Add health checks to our Catalog microservices with checking the health of our PostgreSql data
Health Check are exposed by an app as Http endpoints
Health check endpoints can be configured for various real time monitoring scenarios
Container orchestrator may respond to a failing health check by halting a rolling deployment or restarting a container.
Load balancer might react to an unhealthy app by routing traffic away from the failing instance to a healthy instance.


-----------------------------------------------------------------------------------------------------------------------------------------------------

Vertical Slice Architecture
Organizes our code into feature folders, each feature encapsulated in a single .cs file

Repository Pattern : DDD pattern to keep persistence concerns outside of the system's domain model.
Provides an abstraction of data that app can work with a simple abstraction interfaces

---------------------------------------
Redis Cache : 
Redis is an adv key-value store known for its high performance.
It is often used for caching, session storage, pub/sub system and more.
Redis offers in-memory data storage, result in fast data access
Its support for various data structures make it	versatile for different use cases.
Redis is an excellect choice for microservice architecture primarily due toits inherent distributed characteristics.
Enabling services to access shared data quickly and reducing the load on db.

Implement Proxy Pattern, Decorator Pattern, Scrutor Library.
Implement Cache-aside Pattern / Cache invalidation
Develop Cached BasketRepository and Decorate w/Scrutor Library


Cache-Aside Pattern :
When a client needs to access data, it first checks to see if the data is in the cache.
If the data is in the cache, the client retrieves it from the cache and returns it to the caller.
If the data is not in the cache, the client retrieves it from the db, stores it in the cache, and then returns it to the caller.
Some of caching systems provide read-through and write-through/write-behind operations.
In there systems, client application retrieves data over by cache.
For not supported Caches, it's the responsibility the applications use the cache asn update the cache if there is a cache-miss.
Microservices good example to implement Cache-Aside pattern, it is common to use a distributed cache that is shared across mutluple services.
Cache-aside pattern can improve performance of a microservices architecture, by reducing the number of expensive db calls
To use the cache-aside pattern in a microservice, need to implement a cache layer in your service.
Involve using a cache library or framework, such as Redis or Memcached, or implementing a custom cache solutions

Drawbacks
Cache can introduce additional complexity and may not be suitable for all situations
The cache may need to be invalidated or refreshed when data is updated in the db or data store.
This can require additional coordination between the microservices.
The cache may introduce additional latency if it is located remotely from the microservices that are using it.

Proxy Pattern:
Provides a placeholder for another object to control access to it.
This pattern creates a proxy object that serves as an intermediary for request intended for the original object.
Lazy loading, controlling acces, logging.
It's like having gatekeeper which adds extra behavior or checks before accessing the actual object.

Decorator Pattern:
Dynamically adds behavior to an object without altering its structure.
It involves a set of decorator classes that are used to extend the functionality of the original class without changing its code.
Useful for adding functionalities to objects at runtime.
For example, enhancing a window object with additional features like borders, scrollbars dynamically

How canw e use Decorator Pattern.
Implementation : 
Create abstract decorators that implement the same interface as the object they will extend.
Then concrete decorator classes add additional behavior.
Example:
If you have a BasketRepository class for db operations, you can create a CachedBasketRepository that extends the BasketRepository with caching capabilities.

What is Scrutor Library and why we use it.
.Net library that extends the built-in IOC container of Asp.Net Core.
It provides additional capabilities to scan and register services in more flexible way.
Usage:
Implementing patterns like Decorator in a clean and managaeable way.
It simplifies the process of service registration and decoration in Asp.net Core applications.



------------------------------------
Microservices Synchronous Communication
Synchronous communication is using HTTP or gRPC protocol for returning synchronous response.
The client sends a request and waits for a response from the service
The client code block their thread, until the response reach from the server
The client code block their thread, until the response reach from the server.
The synchronous communication protocols can be HTTP or HTTPs
The client sends a request with using http protocols and waits for a response from the service.
The client call the server and block client their operations.
The client code will continue its task when it receives the HTTP server response

Microservices Asynchronous Communication
The client sends a request but it doesnt wait for the response from the service.
The client should not have blocked a thread while waiting for a response.
AMQP(Advanced Message Queuing Protocol)
Using AMQP protocols, the client sends the message with using message broker systems like Kafka and RabbitMQ queue.
THe message producer does not wait for a response.
Message consume from the subscriber systems in async way and no one waiting for response sunddenly.

GRPC:
It is an open source remote procedure call(RPC) system developed at google.
It is a framework to efficiently connect services and build distributed systems.
It is focused on high performance and uses the HTTP/2 protocol to transport binary messages.
It relies on the Protocol Buffers language to define service contracts
Protocol Buffers allows to define the interface to be used in service to service communication regardless of the programming language
It generates corss-platform client and server bindings for many languages.
Most common usage scenarios include connecting services in microservices style architecture.
So the gRPC framework allows developers to create services that can communicate with each other efficiently
and independently from their preferred programming language.
Once you define a contract with protobuf, this contract can be used by each service to automatically
generate the code that can sets up the communication infrastructure.
This feature simplifies the creation of the service interactions and together with high performance,
makes gRPC the ideal framework for creating microservices and communicating between inter service communications.

how gRPC works ?
A RPC is a form of client server communication that uses a function called, rather than usual Http call.
So in gRPC, a client application can directly call a method on a server application on a different
machine like it is a local object, it making it easy for you to build distributed applications and services.
As with many RPC systems, gRPC is based on the idea of defining a service that specifies methods,
and these can be called remotely with their parameters and return types.
On the server side, the server implements this interface and runs a gRPC server to handle client calls.
On the client side, the client has a setup that provides the same methods as the server.
gRPC client and servers can work and talk to each other in a different of environments, from servers
to your own desktop applications, and that can be written in any language that gRPC supports.


----------------------------------
DDD, CQRS and Clean Architectures

Fundamental architectural styples guiding the development of Ordering microservices.
Clean Architecture organized into 4 layers with class Library project that reference according to clean architecture.



Patterns and Principles of Ordering

1) SOLID, KISS, YAGNI, SoC, DIP principles and DI are foundational.
2) Domain Layer Patterns
   Design a DDD oriented microservice, DDD Tactical Patterns
   Domain Entity pattern, Entity Base classes - Seed Work
   Anemic-domain model vs Rich-domain model
   The Value Object Pattern
   The Aggregate pattern, The Aggregate Root or Root Entity pattern
   Strong Typed IDs Pattern
   Domain Events vs Integration Events
3) Infrastructure Data Layer Patterns
   Repository Pattern
   EF Core ORM - Code First Approach - Migration - Seeding DB
   Value Object Complex Types, EF Aggregate Root Entities
   Entity COnfigurations w? Model Builder - DDD to EF Core Entity Object.
   Raise & Dispatch Domain Events with EF Core and MediatR
4) Presentation Api Layer Patterns
   Minimal APIs
   Asp.Net DI, Routing with lastest asp.net 8 features


SOLID
S-Single Responsibility:
	Each of your components or modules should responsible only one functionality
	A class should have only one reason to change. This means that a class should have only one job or responsibility.
// Before applying SRP
public class Invoice
{
    public void CalculateTotal() { /* ... */ }
    public void PrintInvoice() { /* ... */ }
    public void SaveToFile() { /* ... */ }
}

// After applying SRP
public class Invoice
{
    public void CalculateTotal() { /* ... */ }
}

public class InvoicePrinter
{
    public void PrintInvoice(Invoice invoice) { /* ... */ }
}

public class InvoiceSaver
{
    public void SaveToFile(Invoice invoice) { /* ... */ }
}


O-Open/Closed Principle:
	When we design the system, it should able to extend without changing existing architecture.
	Software entities should be open for extension but closed for modification. This means you should be able to add new functionality without changing existing code.
// Before applying OCP
public class Rectangle
{
    public double Width { get; set; }
    public double Height { get; set; }
}

public class AreaCalculator
{
    public double CalculateArea(Rectangle rectangle)
    {
        return rectangle.Width * rectangle.Height;
    }
}

// After applying OCP
public abstract class Shape
{
    public abstract double CalculateArea();
}

public class Rectangle : Shape
{
    public double Width { get; set; }
    public double Height { get; set; }

    public override double CalculateArea()
    {
        return Width * Height;
    }
}

public class Circle : Shape
{
    public double Radius { get; set; }

    public override double CalculateArea()
    {
        return Math.PI * Radius * Radius;
    }
}

public class AreaCalculator
{
    public double CalculateArea(Shape shape)
    {
        return shape.CalculateArea();
    }
}


L-Liskov's Substitution Principle:
	Systems can be substitute each other easily. In our case we can use plug-in services that we can shift them easily.
	Objects of a superclass should be replaceable with objects of its subclasses without affecting the correctness of the program.
Key Points of LSP

    Behavioral Compatibility: Subtypes must be able to replace their supertypes without altering the desirable properties of the program (e.g., correctness, task performed).
    Preconditions and Postconditions: The preconditions of a subclass method should not be stronger than those of the superclass method. The postconditions of a subclass method should not be weaker than those of the superclass method.
    Invariants: The invariants of the superclass must be preserved in the subclass.

Violations of LSP

Violations of LSP often occur when a subclass overrides a method in a way that breaks the behavior expected by clients of the superclass. This can lead to unexpected errors and bugs.
Example of LSP in C#
Before Applying LSP
public class Bird
{
    public virtual void Fly()
    {
        Console.WriteLine("Flying");
    }
}

public class Sparrow : Bird
{
    // Sparrow can fly
}

public class Ostrich : Bird
{
    public override void Fly()
    {
        throw new InvalidOperationException("Ostrich can't fly!");
    }
}

public class BirdController
{
    public void MakeBirdFly(Bird bird)
    {
        bird.Fly();
    }
}

// Usage
BirdController controller = new BirdController();
controller.MakeBirdFly(new Sparrow()); // Works fine
controller.MakeBirdFly(new Ostrich()); // Throws exception

In the above example, Ostrich cannot fly, which violates the LSP because Ostrich is not a proper substitute for Bird.
After Applying LSP

To comply with LSP, we should refactor the code so that subclasses can be substituted for their base classes without altering the program behavior:
public abstract class Bird
{
    // Common properties and methods for all birds
}

public interface IFlyable
{
    void Fly();
}

public class Sparrow : Bird, IFlyable
{
    public void Fly()
    {
        Console.WriteLine("Flying");
    }
}

public class Ostrich : Bird
{
    // Ostrich specific properties and methods
}

public class BirdController
{
    public void MakeBirdFly(IFlyable bird)
    {
        bird.Fly();
    }
}

// Usage
BirdController controller = new BirdController();
controller.MakeBirdFly(new Sparrow()); // Works fine
// controller.MakeBirdFly(new Ostrich()); // Won't compile, prevents runtime error
This refactoring ensures that the Liskov Substitution Principle is maintained, as Sparrow can be used interchangeably with IFlyable without causing errors, while Ostrich cannot, thus avoiding the incorrect behavior.


I-Interface Segragation:
	States that no code should be forced to depend on methods it doesnt use.
	 It states that no client should be forced to depend on methods it does not use. This principle aims to keep interfaces small and focused, ensuring that implementing classes only need to be concerned with methods that are relevant to them.
	Key Points of ISP

    Client-Specific Interfaces: Interfaces should be specific to the needs of a particular client or group of clients, rather than general-purpose interfaces that contain methods unrelated to some clients.
    Reduce Unnecessary Dependencies: By splitting larger interfaces into smaller ones, classes are not burdened with implementing methods they do not need, reducing the impact of changes and making the system more flexible and easier to maintain.
    Promote Decoupling: Smaller, client-specific interfaces reduce coupling between classes, leading to a more modular and maintainable codebase.

	Violations of ISP

	Violations of ISP occur when an interface contains methods that some implementing classes do not need. This forces classes to implement unnecessary methods or use workarounds, leading to bloated and less maintainable code.
	Example of ISP in C#
	
	Let's consider an example to illustrate the ISP:
	Before Applying ISP
	
	In this example, we have a Worker interface that includes both Work and Eat methods. However, a robot that only works and doesn't need to eat would still be forced to implement the Eat method, which is unnecessary.
public interface IWorker
{
    void Work();
    void Eat();
}

public class HumanWorker : IWorker
{
    public void Work()
    {
        Console.WriteLine("Human working");
    }

    public void Eat()
    {
        Console.WriteLine("Human eating");
    }
}

public class RobotWorker : IWorker
{
    public void Work()
    {
        Console.WriteLine("Robot working");
    }

    public void Eat()
    {
        throw new NotImplementedException("Robot doesn't need to eat");
    }
}
Here, RobotWorker has to implement the Eat method, even though it does not make sense for a robot to eat. This violates ISP because RobotWorker depends on an unnecessary method.
After Applying ISP

To comply with ISP, we should split the IWorker interface into two smaller, more specific interfaces:
public interface IWorkable
{
    void Work();
}

public interface IFeedable
{
    void Eat();
}

public class HumanWorker : IWorkable, IFeedable
{
    public void Work()
    {
        Console.WriteLine("Human working");
    }

    public void Eat()
    {
        Console.WriteLine("Human eating");
    }
}

public class RobotWorker : IWorkable
{
    public void Work()
    {
        Console.WriteLine("Robot working");
    }
}
Benefits of ISP

    Flexibility: Smaller, specific interfaces allow classes to be more flexible in their implementation.
    Maintainability: Changes to an interface are less likely to impact classes that do not use the changed methods, making the codebase easier to maintain.
    Clarity: Smaller interfaces provide clear and focused contracts, making the code more understandable and easier to work with.

By applying the Interface Segregation Principle, we can create a more modular and maintainable system, where classes are not burdened with unnecessary dependencies.



D-Dependency Inversion:
	Stats that high level modules should not depend on low level modules both should depend on abstractions.
	Provide to broke dependency of classes by inverting dependencies, inject dependent classes via contructor.
	Upper level modules or classes and lower level classes must not be dependent on modules
	Lower level modules must be dependent on higher-level modules(interface of modules)
	Without Dependency Inversion :
		(Business)Business Logic -> (Data Access)SqlDatabase
	With Dependency Inversion :
		(Business)Business Logic -> (interface)IRepository <- (Data Access)SqlDatabase

It states that high-level modules should not depend on low-level modules. Both should depend on abstractions. Additionally, abstractions should not depend on details. Details should depend on abstractions.
Key Points of DIP

    Abstractions: Depend on abstractions (e.g., interfaces or abstract classes) rather than concrete implementations.
    Inversion of Control: Achieve inversion of control by using design patterns such as Dependency Injection, Service Locator, or Factory Method.
    Decoupling: Promotes decoupling of high-level and low-level modules, making the code more flexible and easier to maintain.

Violations of DIP

Violations of DIP occur when high-level modules directly depend on low-level modules. This leads to tightly coupled code that is difficult to change and maintain.
Example of DIP in C#

Let's consider an example to illustrate the DIP:
Before Applying DIP

In this example, the LightSwitch class directly depends on the LightBulb class:
public class LightBulb
{
    public void TurnOn()
    {
        Console.WriteLine("LightBulb: On");
    }

    public void TurnOff()
    {
        Console.WriteLine("LightBulb: Off");
    }
}

public class LightSwitch
{
    private LightBulb _lightBulb;

    public LightSwitch(LightBulb lightBulb)
    {
        _lightBulb = lightBulb;
    }

    public void Operate()
    {
        _lightBulb.TurnOn();
    }
}

// Usage
LightBulb lightBulb = new LightBulb();
LightSwitch lightSwitch = new LightSwitch(lightBulb);
lightSwitch.Operate();

In this code, the LightSwitch class is tightly coupled to the LightBulb class. If we want to change the type of the device being switched, we need to modify the LightSwitch class.
After Applying DIP

To comply with DIP, we introduce an abstraction (an interface) that both the high-level module (LightSwitch) and low-level module (LightBulb) depend on:
public interface ISwitchable
{
    void TurnOn();
    void TurnOff();
}

public class LightBulb : ISwitchable
{
    public void TurnOn()
    {
        Console.WriteLine("LightBulb: On");
    }

    public void TurnOff()
    {
        Console.WriteLine("LightBulb: Off");
    }
}

public class Fan : ISwitchable
{
    public void TurnOn()
    {
        Console.WriteLine("Fan: On");
    }

    public void TurnOff()
    {
        Console.WriteLine("Fan: Off");
    }
}

public class LightSwitch
{
    private ISwitchable _device;

    public LightSwitch(ISwitchable device)
    {
        _device = device;
    }

    public void Operate()
    {
        _device.TurnOn();
    }
}

// Usage
ISwitchable lightBulb = new LightBulb();
LightSwitch lightSwitch = new LightSwitch(lightBulb);
lightSwitch.Operate();

ISwitchable fan = new Fan();
LightSwitch fanSwitch = new LightSwitch(fan);
fanSwitch.Operate();

Benefits of DIP

    Flexibility: Code becomes more flexible and easier to extend.
    Maintainability: Changes in low-level modules do not affect high-level modules.
    Testability: Code is easier to test because dependencies can be easily mocked or stubbed.
    Decoupling: Reduces the coupling between high-level and low-level modules, promoting a more modular architecture.

By applying the Dependency Inversion Principle, you create a more maintainable and scalable codebase, where high-level modules are decoupled from low-level modules, and both depend on abstractions. This leads to a more flexible and robust design.

Separation of Concerns (SoC):
	It is one of the core software design principle
	It is a design principle for separating a computer program into distinct sections.
	Isolate the software application into separate sections, manages complexity by partitioning the software system
	Distinguish between the concepts of layer and tiers with certain responsibilities.
	Elements in the software should be unique
	Limits to allocate responsibilities
	Low-coupling, high-cohesion
Separation of Concerns (SoC) is a design principle in software engineering that aims to break a program into distinct sections, each addressing a separate concern. A concern is any piece of interest or responsibility that the software has to address. By separating concerns, you can improve code readability, maintainability, and scalability.
Key Points of SoC

    Modularity: Divide a program into modules, each responsible for a distinct aspect of the application's functionality.
    Maintainability: Simplify the codebase, making it easier to update or fix bugs in one module without affecting others.
    Reusability: Allow modules to be reused across different parts of the application or even in different projects.
    Testability: Facilitate easier testing by isolating different parts of the code.

Examples of SoC
1. MVC Architecture

The Model-View-Controller (MVC) architecture is a common way to implement SoC in web applications. Each component handles a specific aspect of the application:

    Model: Manages the data and business logic.
    View: Manages the display and presentation of data.
    Controller: Manages user input and interactions, updating the Model and View accordingly.

Example in C#:
// Model
public class Product
{
    public int Id { get; set; }
    public string Name { get; set; }
    public decimal Price { get; set; }
}

// View
public class ProductView
{
    public void DisplayProductDetails(Product product)
    {
        Console.WriteLine($"Product: {product.Name}, Price: {product.Price:C}");
    }
}

// Controller
public class ProductController
{
    private readonly Product _product;
    private readonly ProductView _view;

    public ProductController(Product product, ProductView view)
    {
        _product = product;
        _view = view;
    }

    public void UpdateProductName(string name)
    {
        _product.Name = name;
    }

    public void UpdateProductPrice(decimal price)
    {
        _product.Price = price;
    }

    public void DisplayProduct()
    {
        _view.DisplayProductDetails(_product);
    }
}

// Usage
var product = new Product { Id = 1, Name = "Laptop", Price = 999.99M };
var view = new ProductView();
var controller = new ProductController(product, view);

controller.DisplayProduct();
controller.UpdateProductName("Gaming Laptop");
controller.DisplayProduct();

2. Layered Architecture

A layered architecture separates the application into layers, each with a specific responsibility:

    Presentation Layer: Handles the user interface and presentation logic.
    Business Logic Layer: Contains the core functionality and business rules.
    Data Access Layer: Manages data persistence and retrieval.

Example in C#:
// Data Access Layer
public class ProductRepository
{
    public Product GetProductById(int id)
    {
        // Simulate data retrieval from a database
        return new Product { Id = id, Name = "Laptop", Price = 999.99M };
    }

    public void SaveProduct(Product product)
    {
        // Simulate saving to a database
        Console.WriteLine("Product saved to database.");
    }
}

// Business Logic Layer
public class ProductService
{
    private readonly ProductRepository _repository;

    public ProductService(ProductRepository repository)
    {
        _repository = repository;
    }

    public Product GetProduct(int id)
    {
        return _repository.GetProductById(id);
    }

    public void UpdateProduct(Product product)
    {
        _repository.SaveProduct(product);
    }
}

// Presentation Layer
public class ProductController
{
    private readonly ProductService _service;

    public ProductController(ProductService service)
    {
        _service = service;
    }

    public void DisplayProduct(int id)
    {
        var product = _service.GetProduct(id);
        Console.WriteLine($"Product: {product.Name}, Price: {product.Price:C}");
    }

    public void UpdateProduct(int id, string name, decimal price)
    {
        var product = _service.GetProduct(id);
        product.Name = name;
        product.Price = price;
        _service.UpdateProduct(product);
    }
}

// Usage
var repository = new ProductRepository();
var service = new ProductService(repository);
var controller = new ProductController(service);

controller.DisplayProduct(1);
controller.UpdateProduct(1, "Gaming Laptop", 1299.99M);
controller.DisplayProduct(1);
Benefits of SoC

    Improved Readability: Each module has a clear and distinct responsibility, making the code easier to understand.
    Enhanced Maintainability: Changes to one part of the application are less likely to impact others, reducing the risk of bugs.
    Reusability: Modules can often be reused in other parts of the application or in different projects.
    Better Collaboration: Teams can work on different modules independently, facilitating parallel development.
    Easier Testing: Modules can be tested in isolation, ensuring that individual parts work correctly before integrating them.

By applying the principle of Separation of Concerns, you can create a well-organized, modular, and maintainable codebase, leading to more robust and scalable software.

------------------------------------------------------------------------
KISS (Keep It Simple, Stupid) :
KISS is a design principle that emphasizes simplicity in software development. The idea is to avoid unnecessary complexity and overengineering, which can lead to more maintainable and understandable code.
Key Points of KISS

    Simplicity: Strive to keep designs as simple as possible.
    Avoid Overengineering: Do not add functionality that is not needed.
    Clarity: Write code that is easy to understand and maintain.
    Efficiency: Simple designs are often more efficient and easier to optimize.

Examples of KISS in Practice
Example 1: Simplifying Conditional Logic

Before Applying KISS:
public string GetUserStatus(int age)
{
    if (age < 0)
    {
        return "Invalid age";
    }
    else
    {
        if (age < 13)
        {
            return "Child";
        }
        else if (age < 18)
        {
            return "Teenager";
        }
        else if (age < 65)
        {
            return "Adult";
        }
        else
        {
            return "Senior";
        }
    }
}
After Applying KISS:
public string GetUserStatus(int age)
{
    if (age < 0)
        return "Invalid age";
    if (age < 13)
        return "Child";
    if (age < 18)
        return "Teenager";
    if (age < 65)
        return "Adult";
    return "Senior";
}
By removing unnecessary nesting, the code becomes simpler and easier to read.


Example 2: Simplifying Class Design
Before Applying KISS:
public class UserManager
{
    private readonly IUserRepository _userRepository;
    private readonly IEmailService _emailService;
    private readonly ILogger _logger;

    public UserManager(IUserRepository userRepository, IEmailService emailService, ILogger logger)
    {
        _userRepository = userRepository;
        _emailService = emailService;
        _logger = logger;
    }

    public void RegisterUser(string username, string email)
    {
        var user = new User { Username = username, Email = email };
        _userRepository.Save(user);
        _emailService.SendWelcomeEmail(email);
        _logger.Log("User registered: " + username);
    }
}
After Applying KISS:
public class UserManager
{
    private readonly IUserRepository _userRepository;
    private readonly IEmailService _emailService;

    public UserManager(IUserRepository userRepository, IEmailService emailService)
    {
        _userRepository = userRepository;
        _emailService = emailService;
    }

    public void RegisterUser(string username, string email)
    {
        var user = new User { Username = username, Email = email };
        _userRepository.Save(user);
        _emailService.SendWelcomeEmail(email);
    }
}
By removing the logging functionality from the UserManager class, the class becomes simpler. Logging can be handled by a decorator or aspect-oriented programming (AOP) if needed.


Example 3: Simplifying Method Logic
Before Applying KISS:
public decimal CalculateTotalPrice(List<decimal> prices, decimal discount, bool includeTax)
{
    decimal totalPrice = 0;
    foreach (var price in prices)
    {
        totalPrice += price;
    }

    if (discount > 0)
    {
        totalPrice -= discount;
    }

    if (includeTax)
    {
        totalPrice *= 1.2M; // Assuming 20% tax
    }

    return totalPrice;
}
After Applying KISS:
public decimal CalculateTotalPrice(List<decimal> prices, decimal discount, bool includeTax)
{
    var totalPrice = prices.Sum();

    totalPrice -= discount;

    if (includeTax)
    {
        totalPrice *= 1.2M; // Assuming 20% tax
    }

    return totalPrice;
}
By using LINQ's Sum() method, the code becomes more concise and easier to understand.
Benefits of KISS

    Readability: Simpler code is easier to read and understand.
    Maintainability: Reduces the risk of bugs and makes the code easier to maintain.
    Performance: Often leads to more efficient code as simpler solutions are usually faster.
    Development Speed: Simplifies the development process, allowing for faster iteration and delivery.

Conclusion

Applying the KISS principle helps in writing clean, efficient, and maintainable code. It encourages developers to avoid unnecessary complexity and focus on solving the problem at hand in the simplest way possible. This leads to a more robust and scalable codebase, ultimately benefiting both developers and users.

-----------------------------------------------------
YAGNI (You Aren't Gonna Need It):
YAGNI is a principle of software development that states you should not add functionality until it is necessary. The idea is to avoid the temptation to write code that anticipates future needs, which often leads to wasted effort and unnecessary complexity.
Key Points of YAGNI

    Avoid Premature Optimization: Focus on current requirements, not hypothetical future needs.
    Simplify Codebase: Write only the code that is needed for the current functionality.
    Reduce Maintenance: Less code means fewer bugs and less effort required for maintenance.
    Improve Focus: Concentrate on delivering features that add immediate value to users.

Examples of YAGNI in Practice
Example 1: Feature Development

Before Applying YAGNI:
public class User
{
    public string Username { get; set; }
    public string Email { get; set; }
    public string PhoneNumber { get; set; } // Future feature: SMS notifications

    public User(string username, string email)
    {
        Username = username;
        Email = email;
        PhoneNumber = ""; // Placeholder for future feature
    }
}
In this example, the PhoneNumber property is added in anticipation of a future feature (SMS notifications) that is not currently required.

After Applying YAGNI:
public class User
{
    public string Username { get; set; }
    public string Email { get; set; }

    public User(string username, string email)
    {
        Username = username;
        Email = email;
    }
}

By removing the PhoneNumber property, the class is simplified to include only the currently necessary functionality.
Example 2: Avoiding Overly Complex Interfaces
Before Applying YAGNI:
public interface IReportGenerator
{
    void GeneratePDFReport();
    void GenerateExcelReport(); // Future feature: Excel report generation
    void GenerateWordReport();  // Future feature: Word report generation
}

public class PDFReportGenerator : IReportGenerator
{
    public void GeneratePDFReport()
    {
        // Generate PDF report
    }

    public void GenerateExcelReport()
    {
        // Not implemented yet
        throw new NotImplementedException();
    }

    public void GenerateWordReport()
    {
        // Not implemented yet
        throw new NotImplementedException();
    }
}
The interface includes methods for generating Excel and Word reports, which are not currently needed, leading to unimplemented methods and potential confusion.

After Applying YAGNI:
public interface IReportGenerator
{
    void GeneratePDFReport();
}

public class PDFReportGenerator : IReportGenerator
{
    public void GeneratePDFReport()
    {
        // Generate PDF report
    }
}
By simplifying the interface to include only the currently required method, the design is cleaner and easier to understand.
Example 3: Refactoring Classes

Before Applying YAGNI:
public class UserManager
{
    public void RegisterUser(string username, string email)
    {
        // Registration logic
    }

    public void RegisterUser(string username, string email, string phoneNumber)
    {
        // Registration logic with phone number
    }
}
The UserManager class includes an overloaded method anticipating future requirements (registering with a phone number) that are not currently needed.

After Applying YAGNI
public class UserManager
{
    public void RegisterUser(string username, string email)
    {
        // Registration logic
    }
}
By removing the unnecessary overload, the class is simplified to handle the current requirements only.
Benefits of YAGNI

    Efficiency: Focuses development efforts on delivering immediate value.
    Simplicity: Reduces complexity in the codebase, making it easier to understand and maintain.
    Agility: Allows for quicker adaptation to changing requirements, as the codebase is not burdened with unused features.
    Cost-Effective: Saves time and resources by avoiding unnecessary work on features that may never be used.

Conclusion

The YAGNI principle encourages developers to resist the urge to build features or add functionality that is not immediately necessary. By adhering to YAGNI, you can create a more maintainable, focused, and efficient codebase, ultimately leading to better software and a more streamlined development process.

---------------------------------------------------------
Anemic-domain model vs Rich-domain mode:
The terms "Anemic Domain Model" and "Rich Domain Model" describe different approaches to designing domain models in object-oriented programming, particularly within the context of Domain-Driven Design (DDD). These approaches differ in how they handle the encapsulation of behavior (business logic) and data (state) within domain objects.
Anemic Domain Model

An Anemic Domain Model is characterized by domain objects that primarily contain data (state) without behavior (business logic). In this approach, domain objects are often simple data containers, and most of the business logic resides in separate service or procedural code outside these objects.
Characteristics of Anemic Domain Model:

    Data-Focused: Domain objects are primarily responsible for holding data.
    Procedural Design: Business logic is typically implemented in separate service classes or procedural code.
    Anemic Entities: Entities lack methods that directly manipulate their own data or enforce business rules.
    Low Cohesion: Related behavior may be scattered across different classes, leading to lower cohesion.

Example of Anemic Domain Model:
public class Order
{
    public int OrderId { get; set; }
    public DateTime OrderDate { get; set; }
    public decimal TotalAmount { get; set; }
}

public class OrderService
{
    public void ProcessOrder(Order order)
    {
        // Business logic for processing the order
    }

    public void CalculateTotalAmount(Order order)
    {
        // Calculate total amount logic
    }
}

In this example, the Order class is primarily a data structure, while the OrderService contains methods responsible for business logic.
Rich Domain Model

A Rich Domain Model, on the other hand, encapsulates both data (state) and behavior (business logic) within domain objects themselves. This approach aligns closely with the principles of object-oriented design, where objects are not just passive data holders but active participants in the system's behavior.
Characteristics of Rich Domain Model:

    Behavior-Focused: Domain objects contain methods that encapsulate business rules and logic.
    Encapsulation: Business logic is embedded within domain objects, promoting high cohesion.
    Domain Expertise: Objects embody the domain knowledge and responsibilities.
    Complexity: May involve more complex interactions between objects.

Example of Rich Domain Model:
public class Order
{
    public int OrderId { get; private set; }
    public DateTime OrderDate { get; private set; }
    public decimal TotalAmount { get; private set; }

    private List<OrderItem> _orderItems = new List<OrderItem>();

    public IReadOnlyCollection<OrderItem> OrderItems => _orderItems;

    public Order(int orderId, DateTime orderDate)
    {
        OrderId = orderId;
        OrderDate = orderDate;
    }

    public void AddOrderItem(OrderItem orderItem)
    {
        _orderItems.Add(orderItem);
        CalculateTotalAmount();
    }

    private void CalculateTotalAmount()
    {
        TotalAmount = _orderItems.Sum(item => item.Quantity * item.UnitPrice);
    }
}

public class OrderItem
{
    public int ProductId { get; private set; }
    public int Quantity { get; private set; }
    public decimal UnitPrice { get; private set; }

    public OrderItem(int productId, int quantity, decimal unitPrice)
    {
        ProductId = productId;
        Quantity = quantity;
        UnitPrice = unitPrice;
    }
}
In this example, the Order class contains business logic (e.g., CalculateTotalAmount) directly related to its operations, encapsulating both data and behavior within the domain object itself.
Considerations

    Complexity vs Simplicity: An Anemic Domain Model can be simpler and easier to manage in smaller applications or where domain logic is minimal. A Rich Domain Model is more complex but can provide clearer domain semantics and encapsulation.

    Evolution: A Rich Domain Model tends to evolve better as business requirements change, as domain objects can directly evolve with new behaviors and rules.

    Practicality: In some cases, a hybrid approach may be appropriate, where simple data structures are complemented by services or strategies to handle more complex business logic.

In conclusion, the choice between Anemic Domain Model and Rich Domain Model depends on the specific requirements, complexity, and scalability needs of the application. Rich Domain Models are often favored in DDD for their ability to encapsulate domain knowledge and enforce business rules directly within domain objects. However, the simplicity of Anemic Domain Models can sometimes provide a pragmatic solution, especially in simpler systems or where domain logic is minimal.
---------------------------------------------------------------------------------------------
Value Object Pattern:
The Value Object Pattern is a design pattern used in software development to represent immutable types that are distinguishable only by the values they encapsulate. Unlike entities, which are identified by their identity, value objects derive their equality from their value rather than a unique identifier. This pattern is particularly useful in Domain-Driven Design (DDD) to model concepts that are defined by their attributes rather than their identity.
Characteristics of Value Objects

    Immutable: Once created, a value object's state cannot be modified.
    Equality by Value: Two value objects with the same values are considered equal.
    No Identity: Value objects have no conceptual identity beyond their values.
    Self-Validating: Ensure validity upon creation or through methods, but don't change state.

Benefits of Value Objects

    Clarity and Expressiveness: They model domain concepts directly, enhancing the readability and expressiveness of the code.

    Immutability: Since they are immutable, they simplify concurrent programming and reduce the risk of unintended side effects.

    Type Safety: They enforce strong typing and encapsulate behavior specific to their domain.

Example of Value Object Pattern in C#
public class Money : IEquatable<Money>
{
    public decimal Amount { get; }
    public string Currency { get; }

    public Money(decimal amount, string currency)
    {
        Amount = amount;
        Currency = currency;
    }

    public override bool Equals(object obj)
    {
        return Equals(obj as Money);
    }

    public bool Equals(Money other)
    {
        if (other is null)
            return false;

        return Amount == other.Amount && Currency == other.Currency;
    }

    public override int GetHashCode()
    {
        return HashCode.Combine(Amount, Currency);
    }

    // Custom method for adding money
    public Money Add(Money other)
    {
        if (other.Currency != Currency)
            throw new InvalidOperationException("Cannot add money of different currencies.");

        return new Money(Amount + other.Amount, Currency);
    }
}

public class Program
{
    public static void Main()
    {
        Money money1 = new Money(100, "USD");
        Money money2 = new Money(50, "USD");

        Money total = money1.Add(money2);
        
        Console.WriteLine($"Total amount: {total.Amount} {total.Currency}"); // Output: Total amount: 150 USD
    }
}
Use Cases for Value Objects

    Money: Represents a monetary amount with a specific currency.
    Date Range: Represents a range of dates with a start and end date.
    Address: Represents a physical address with street, city, state, and postal code.
    Temperature: Represents a temperature with a value and a unit (e.g., Celsius or Fahrenheit).

Guidelines for Implementing Value Objects

    Immutable: Ensure that the state of the value object cannot be changed after creation.

    Equality: Implement equality methods (Equals and GetHashCode) based on the values encapsulated.

    Behavior Methods: Include methods that operate on the values encapsulated within the value object.

Conclusion

The Value Object Pattern is a powerful tool in domain modeling, particularly in scenarios where identity is not important, and objects are distinguished solely by their attributes. By encapsulating immutable state and behaviors specific to their domain, value objects promote clearer, more expressive, and maintainable code. They play a crucial role in Domain-Driven Design by representing essential concepts within the domain in a meaningful and type-safe manner.
---------------------------------------------------------------------------------------------------

The Aggregate pattern:
The Aggregate pattern is a design pattern used in Domain-Driven Design (DDD) to encapsulate a cluster of related domain objects into a single unit. It helps to manage the complexity of domain models and ensures consistency and transactional integrity within the domain. Understanding aggregates is crucial for designing scalable and maintainable domain models.
Key Concepts of the Aggregate Pattern

    Aggregate Root:
        An aggregate has a root entity, known as the Aggregate Root, which acts as the entry point to the aggregate.
        The aggregate root is responsible for ensuring the consistency and validity of the entire aggregate.
        It is the only part of the aggregate that external entities can directly reference.

    Consistency Boundary:
        All operations within an aggregate should maintain its consistency.
        Changes to the internal state of objects within the aggregate should be performed through the aggregate root.

    Transactional Scope:
        Aggregates are typically treated as transactional boundaries.
        Changes to objects within the aggregate are committed or rolled back together to maintain consistency.

    Direct Access:
        External entities can only hold references to the aggregate root.
        They cannot directly reference or modify objects within the aggregate without going through the root.

Example of Aggregate Pattern

Let's consider an example of an e-commerce system with Order and OrderItem entities. In this case, Order is an aggregate root, and OrderItem objects are part of the aggregate.
public class Order
{
    public int OrderId { get; private set; }
    public DateTime OrderDate { get; private set; }
    private List<OrderItem> _orderItems = new List<OrderItem>();

    // Navigation property
    public IReadOnlyCollection<OrderItem> OrderItems => _orderItems.AsReadOnly();

    private Order()
    {
        // Private constructor for Entity Framework or other ORM
    }

    public Order(DateTime orderDate)
    {
        OrderDate = orderDate;
    }

    public void AddOrderItem(int productId, int quantity, decimal unitPrice)
    {
        // Perform validation or business logic
        var orderItem = new OrderItem(productId, quantity, unitPrice);
        _orderItems.Add(orderItem);
    }

    public void RemoveOrderItem(OrderItem orderItem)
    {
        // Perform validation or business logic
        _orderItems.Remove(orderItem);
    }

    // Other methods and business logic
}

public class OrderItem
{
    public int OrderItemId { get; private set; }
    public int ProductId { get; private set; }
    public int Quantity { get; private set; }
    public decimal UnitPrice { get; private set; }

    private OrderItem()
    {
        // Private constructor for Entity Framework or other ORM
    }

    public OrderItem(int productId, int quantity, decimal unitPrice)
    {
        ProductId = productId;
        Quantity = quantity;
        UnitPrice = unitPrice;
    }

    // Other methods and business logic
}
In this example:

    Order is the aggregate root, responsible for managing the OrderItems.
    External entities interact with Order to add or remove OrderItems.
    OrderItem objects cannot exist outside the context of an Order and are managed through the aggregate root.

Guidelines for Implementing Aggregates

    Identify Aggregate Roots: Determine which entities should act as aggregate roots based on their lifecycle and transactional boundaries.

    Ensure Consistency: All operations within the aggregate should maintain its internal consistency.

    Transactional Boundaries: Treat aggregates as transactional boundaries to ensure that changes are committed or rolled back atomically.

    Encapsulate Invariants: Encapsulate business rules and invariants within the aggregate to maintain its validity.

When to Use Aggregates

    Complex Domains: Use aggregates to manage complex interactions and relationships between domain objects.

    Consistency Requirements: Use aggregates to ensure consistency and transactional integrity within the domain.

Benefits of the Aggregate Pattern

    Modularity: Encapsulates related domain objects into cohesive units, improving maintainability.

    Transactional Integrity: Ensures that changes to the aggregate are transactionally consistent.

    Scalability: Helps in designing scalable domain models by managing complexity and reducing dependencies.

Conclusion

The Aggregate pattern is a fundamental concept in Domain-Driven Design that helps in designing cohesive, scalable, and maintainable domain models. By defining transactional boundaries and encapsulating related domain objects, aggregates enforce consistency and ensure that domain logic is applied consistently across the application. Understanding and properly implementing aggregates is crucial for designing robust and effective domain-driven applications.
--------------------------------------------------------------------------------------
Integration Events:
Integration Events are a key concept in event-driven architectures and microservices, where they facilitate communication and coordination between different parts of a system or between multiple systems. These events represent something significant that has happened within the system and are used to notify other parts of the system or external systems about these occurrences. Integration Events are particularly useful in scenarios where multiple microservices need to react to changes in a decoupled and asynchronous manner.
Key Characteristics of Integration Events

    Asynchronous Communication: Events are used to communicate changes or occurrences in a decoupled manner, allowing services to react independently and asynchronously.

    Loose Coupling: Services producing events do not need to know which services (if any) are consuming these events. This promotes loose coupling between different parts of the system.

    Event Payload: Events typically carry relevant information (payload) related to the event, which can include identifiers, timestamps, and specific data related to the event occurrence.

    Publish-Subscribe Model: Events follow a publish-subscribe (pub/sub) pattern, where publishers publish events to a message broker or event bus, and subscribers consume the events they are interested in.

Example Scenario

Consider an e-commerce application where an order is placed. This event triggers several actions across different microservices:

    Order Service publishes an OrderPlacedEvent containing details about the order.
    Inventory Service subscribes to OrderPlacedEvent and updates the available inventory for the ordered items.
    Notification Service subscribes to OrderPlacedEvent and sends a confirmation email to the customer.

Benefits of Integration Events

    Decoupling: Services are loosely coupled, enabling independent development, scalability, and resilience.

    Scalability: Events facilitate horizontal scaling by distributing work across multiple instances of subscribing services.

    Reliability: Event-driven architectures are resilient to failures in individual services as events can be retried or processed by alternative subscribers.

    Flexibility: Allows new functionalities to be added easily by subscribing to relevant events without modifying existing services.

Implementing Integration Events

Integration Events can be implemented using various messaging technologies such as:

    Message Brokers: Systems like RabbitMQ, Apache Kafka, or Azure Service Bus can serve as the intermediary for publishing and consuming events.

    Event Bus: An internal component or service within the system that manages the routing and delivery of events between publishers and subscribers.

Considerations for Integration Events

    Event Schema: Define clear schemas for events to ensure compatibility and consistency across different services.

    Eventual Consistency: Embrace eventual consistency in distributed systems, as events may be processed in different orders or with delays.

    Error Handling: Implement mechanisms for handling errors and retries, ensuring reliable event delivery.

Conclusion

Integration Events play a crucial role in enabling decoupled communication and coordination in distributed systems and microservices architectures. By leveraging events, systems can achieve higher scalability, flexibility, and resilience while maintaining loose coupling between services. Understanding how to design and implement integration events effectively is essential for building modern, responsive, and scalable software architectures.


Example Scenario: E-commerce Order Processing
Step 1: Define the Integration Event

First, define the structure of the Integration Event (OrderPlacedIntegrationEvent) that will be published when an order is placed:

public class OrderPlacedIntegrationEvent
{
    public int OrderId { get; set; }
    public DateTime OrderDate { get; set; }
    public string CustomerEmail { get; set; }
    public List<OrderItem> OrderItems { get; set; }
    
    // Additional properties as needed
}

public class OrderItem
{
    public int ProductId { get; set; }
    public string ProductName { get; set; }
    public int Quantity { get; set; }
    public decimal UnitPrice { get; set; }
}

Step 2: Publish Integration Event in Order Service

In your Order Service, publish the OrderPlacedIntegrationEvent when an order is successfully placed:

public class OrderService
{
    private readonly IMessageBus _messageBus; // Assume an IMessageBus interface for publishing events

    public OrderService(IMessageBus messageBus)
    {
        _messageBus = messageBus;
    }

    public void PlaceOrder(int orderId, string customerEmail, List<OrderItem> orderItems)
    {
        // Logic to place order...

        // Publish integration event
        var orderPlacedEvent = new OrderPlacedIntegrationEvent
        {
            OrderId = orderId,
            OrderDate = DateTime.UtcNow,
            CustomerEmail = customerEmail,
            OrderItems = orderItems
        };

        _messageBus.Publish(orderPlacedEvent);
    }
}

Step 3: Subscribe to Integration Event in Inventory Service

The Inventory Service subscribes to OrderPlacedIntegrationEvent to update its inventory:

public class InventoryService
{
    public void HandleOrderPlaced(OrderPlacedIntegrationEvent orderPlacedEvent)
    {
        // Logic to update inventory based on order items
        foreach (var orderItem in orderPlacedEvent.OrderItems)
        {
            // Update inventory for orderItem.ProductId and orderItem.Quantity
            Console.WriteLine($"Updating inventory for Product ID {orderItem.ProductId} by {orderItem.Quantity} units.");
        }
    }
}

Step 4: Subscribe to Integration Event in Notification Service

The Notification Service subscribes to OrderPlacedIntegrationEvent to send a confirmation email:

public class NotificationService
{
    public void HandleOrderPlaced(OrderPlacedIntegrationEvent orderPlacedEvent)
    {
        // Logic to send confirmation email to customer
        Console.WriteLine($"Sending confirmation email to {orderPlacedEvent.CustomerEmail}...");
        // Send email logic here
    }
}

Step 5: Configuring Message Broker (Assumed)

Assuming you have a message broker (e.g., RabbitMQ, Kafka) configured in your infrastructure, both Inventory Service and Notification Service would connect to this message broker to subscribe to OrderPlacedIntegrationEvent and receive events published by the Order Service.
Summary

    Order Service: Publishes OrderPlacedIntegrationEvent when an order is placed.
    Inventory Service: Subscribes to OrderPlacedIntegrationEvent to update inventory.
    Notification Service: Subscribes to OrderPlacedIntegrationEvent to send a confirmation email.
    Message Broker: Acts as the intermediary for publishing and subscribing to integration events.

This example demonstrates how Integration Events enable loosely coupled communication between different parts of a system. Each service focuses on its core responsibilities (ordering, inventory management, notification) without directly coupling to others, promoting scalability, resilience, and maintainability in a distributed system architecture.


-----------------------------------------------------------------------------------
Domain Events:
Domain Events are a fundamental concept in Domain-Driven Design (DDD) that enable communication and encapsulation of domain-specific occurrences or state changes within a domain model. Unlike Integration Events, which are used for system-level communication between different services or components, Domain Events are internal to a single bounded context or domain model. They represent meaningful changes or events that occur within the domain and are typically used to trigger side effects or reactions within the same domain.
Key Characteristics of Domain Events

    Domain-Specific: Events represent significant changes or occurrences within a specific domain or bounded context.

    Encapsulation of Business Logic: Events encapsulate domain-specific business rules and logic related to the occurrence they represent.

    Asynchronous Communication: Events are often used to trigger asynchronous reactions or side effects within the domain model.

    Publish-Subscribe Model: Like Integration Events, Domain Events follow a publish-subscribe pattern within the same bounded context.

Example Scenario

Let's consider an example of an e-commerce application where a shipment is confirmed, triggering a domain event to update the order status and notify the customer.
Step 1: Define the Domain Event

Define the structure of the Domain Event (ShipmentConfirmedDomainEvent) that represents the confirmation of a shipment:

csharp

public class ShipmentConfirmedDomainEvent
{
    public int OrderId { get; }
    public DateTime ShipmentDate { get; }

    public ShipmentConfirmedDomainEvent(int orderId, DateTime shipmentDate)
    {
        OrderId = orderId;
        ShipmentDate = shipmentDate;
    }
}

Step 2: Raise Domain Event in Domain Entity

In your domain entity (e.g., Order entity), raise the ShipmentConfirmedDomainEvent when a shipment is confirmed:

csharp

public class Order
{
    public int OrderId { get; private set; }
    public DateTime OrderDate { get; private set; }
    public bool IsShipped { get; private set; }

    public void ConfirmShipment(DateTime shipmentDate)
    {
        // Perform logic to confirm shipment...

        // Raise domain event
        var shipmentConfirmedEvent = new ShipmentConfirmedDomainEvent(OrderId, shipmentDate);
        DomainEvents.Raise(shipmentConfirmedEvent);
    }
}

Step 3: Subscribe to Domain Event

Subscribe to ShipmentConfirmedDomainEvent within the same bounded context to react to the shipment confirmation:

csharp

public class OrderStatusUpdater
{
    public void HandleShipmentConfirmed(ShipmentConfirmedDomainEvent domainEvent)
    {
        // Logic to update order status, send notifications, etc.
        Console.WriteLine($"Order {domainEvent.OrderId} has been shipped on {domainEvent.ShipmentDate}.");
    }
}

Step 4: DomainEvents Mechanism

Implement a mechanism (DomainEvents static class or similar) to manage subscriptions and event dispatching within the domain:

csharp

public static class DomainEvents
{
    private static List<Action<object>> _handlers = new List<Action<object>>();

    public static void Register<T>(Action<T> handler) where T : class
    {
        _handlers.Add(o => handler(o as T));
    }

    public static void Raise<T>(T args) where T : class
    {
        foreach (var handler in _handlers)
        {
            handler(args);
        }
    }
}

Step 5: Wiring Up Handlers

Wire up the event handlers (subscriptions) during application startup or configuration:

csharp

public class Program
{
    public static void Main()
    {
        // Register event handlers
        DomainEvents.Register<ShipmentConfirmedDomainEvent>(new OrderStatusUpdater().HandleShipmentConfirmed);

        // Simulate order processing and shipment confirmation
        var order = new Order();
        order.ConfirmShipment(DateTime.UtcNow);
    }
}

Summary

    Domain Event (ShipmentConfirmedDomainEvent): Represents the confirmation of a shipment within the domain.
    Domain Entity (Order): Raises the domain event (ShipmentConfirmedDomainEvent) when a shipment is confirmed.
    Event Handlers (OrderStatusUpdater): Subscribes to the domain event (ShipmentConfirmedDomainEvent) to handle the shipment confirmation and update order status.
    DomainEvents Mechanism: Manages the registration and dispatching of domain events within the domain.

This example illustrates how Domain Events enable encapsulation of domain-specific events and facilitate decoupled communication and side effects within the same bounded context in a domain-driven architecture. Domain Events help maintain separation of concerns and promote scalability and flexibility in complex domain models.

-------------------------------------------------------------------------
Repository Pattern:
The Repository Pattern is a design pattern commonly used in software development to abstract the data access layer from the rest of the application. It provides a mechanism to encapsulate the logic required to access data sources such as databases, web services, or in-memory collections. This pattern promotes separation of concerns by isolating the application/business logic from the details of data persistence and retrieval.
Key Concepts of the Repository Pattern

    Abstraction of Data Access: The Repository acts as an intermediary between the domain/entity objects and the data source. It provides a set of methods to perform CRUD (Create, Read, Update, Delete) operations on domain objects without exposing the underlying data access logic.

    Encapsulation of Query Logic: The Repository encapsulates the query logic required to retrieve data. This allows the application to interact with a simple interface, hiding the complexities of querying from the rest of the codebase.

    Promotes Testability: By abstracting data access behind interfaces, repositories make it easier to mock data sources during unit testing. This improves testability and allows developers to isolate the business logic from the database.

    Single Responsibility Principle: Repositories adhere to the Single Responsibility Principle (SRP) by focusing solely on data access operations. They do not contain business logic, which is handled by other components in the application.

Example Implementation

Let's illustrate the Repository Pattern with a simple example in C# using an interface for a repository and an implementation using Entity Framework Core for data access.
Step 1: Define Repository Interface

Define an interface (IRepository) that outlines the operations to be supported by repositories:

csharp

public interface IRepository<TEntity> where TEntity : class
{
    TEntity GetById(int id);
    IEnumerable<TEntity> GetAll();
    void Add(TEntity entity);
    void Update(TEntity entity);
    void Delete(TEntity entity);
    // Additional methods as needed (e.g., Find, SaveChanges)
}

Step 2: Implement Repository with Entity Framework Core

Implement the IRepository interface using Entity Framework Core for data access:

csharp

public class Repository<TEntity> : IRepository<TEntity> where TEntity : class
{
    private readonly DbContext _dbContext;
    private readonly DbSet<TEntity> _dbSet;

    public Repository(DbContext dbContext)
    {
        _dbContext = dbContext;
        _dbSet = _dbContext.Set<TEntity>();
    }

    public TEntity GetById(int id)
    {
        return _dbSet.Find(id);
    }

    public IEnumerable<TEntity> GetAll()
    {
        return _dbSet.ToList();
    }

    public void Add(TEntity entity)
    {
        _dbSet.Add(entity);
    }

    public void Update(TEntity entity)
    {
        _dbSet.Attach(entity);
        _dbContext.Entry(entity).State = EntityState.Modified;
    }

    public void Delete(TEntity entity)
    {
        _dbSet.Remove(entity);
    }

    // Additional methods can be added based on specific requirements
}

Step 3: Using the Repository

Use the Repository implementation in your application to interact with entities:

csharp

public class ProductService
{
    private readonly IRepository<Product> _productRepository;

    public ProductService(IRepository<Product> productRepository)
    {
        _productRepository = productRepository;
    }

    public void AddProduct(Product product)
    {
        _productRepository.Add(product);
        _productRepository.SaveChanges(); // Example: SaveChanges method if supported
    }

    public IEnumerable<Product> GetAllProducts()
    {
        return _productRepository.GetAll();
    }

    public void UpdateProduct(Product product)
    {
        _productRepository.Update(product);
        _productRepository.SaveChanges(); // Example: SaveChanges method if supported
    }

    public void DeleteProduct(int productId)
    {
        var product = _productRepository.GetById(productId);
        if (product != null)
        {
            _productRepository.Delete(product);
            _productRepository.SaveChanges(); // Example: SaveChanges method if supported
        }
    }
}

Step 4: Dependency Injection and Usage

Configure Dependency Injection (DI) to inject the Repository implementation into services or controllers:

csharp

public class Startup
{
    public void ConfigureServices(IServiceCollection services)
    {
        services.AddDbContext<AppDbContext>(options =>
            options.UseSqlServer(Configuration.GetConnectionString("DefaultConnection")));

        services.AddScoped<IRepository<Product>, Repository<Product>>();
        services.AddScoped<ProductService>();

        // Other configurations...
    }
}

Benefits of the Repository Pattern

    Separation of Concerns: Separates the business logic from the data access logic, promoting cleaner and more maintainable code.

    Testability: Facilitates unit testing by allowing mock implementations of repositories, improving test coverage and reliability.

    Flexibility: Easily switch between different data access strategies (e.g., Entity Framework, Dapper) without impacting the rest of the application.

    Centralized Data Access Logic: Provides a centralized place to manage common data access patterns and practices, enhancing consistency and reducing duplication.

Considerations

    Complexity: Avoid over-engineering repositories for simple CRUD operations. Use them where the complexity or need for abstraction justifies their use.

    Performance: Consider performance implications, especially when dealing with large datasets or complex queries. Optimize data access strategies accordingly.

    Concurrency and Transactions: Ensure that repositories handle concurrency and transactions appropriately, depending on the data source and application requirements.

Conclusion

The Repository Pattern is a valuable design pattern for managing data access in applications, providing a structured way to interact with data sources while promoting separation of concerns and enhancing testability and maintainability. When implemented correctly, repositories simplify the integration of data access logic into the broader application architecture, supporting scalable and efficient development practices.


---------------------------------------------------------

Domain Driven Design:
	DDD has been around since Eric Evans published his book about the subject  in 2003
	DDD is solving a complex problem is to break the problem into smaller parts and focus on smaller problems that are relative easy.
	A complex domain may contain sub domains. And some of sub domains can combine and grouping with each other for common rules and responsibilities.

	Types of DDD:
		Strategic DDD:
			Understanding and modeling the business domain.
			It involves identifying the different domains, their subdomains, and how they interact with each other

		Tactical DDD:
			Implementation details and provides design patterns.
			Including patterns life Entities, Value Objects, Aggregates, etc.
	
	Domain Concepts:
		Domain,Sub Domain, Ubiquitous Langauge, Bounded Context, Context Mapping
	Domain:
		The sphere of knowledge and activity around which the application logic revolves.
		Represents the problem space- the area of expertise or business need that the software addressess.
	SubDomain:
		Represents a specific area of expertise within the overall domain.
	Ubiquitous Langauge:
		Common Language used by developers and domain experts to ensure clarity and consistency.
		
Clean Architecture:
Introduced by Robert C. Martin also know as Uncle Bob.
Software architecture design that aims to separate concerns and create systems that are independent of frameworks,UI and DB
Leads to system that are more maintainable, flexible, and adaptable to changes.

Key Principles:
	Independence of Frameworks:
		The system is not tightly coupled with a specific framework, which makes it adaptable to changes in frameworks and tools.
	Testable:
		The business rules can be tested without the UI, DB, web servers or any external element.
	UI Agnostic:
		The UI can change easilym without changing the rest of the system.
	Database Agnostic:
		Business rules are not bound to the database, decoupled from the underlying data store.
	External System Agnostic:
		Business rules dont know anything about the outside world, isolated.

	Layers : 
	Enity Layer :
		Contains enterprise-wide business rules.
		Entitues encapsulate the most general and high level rules
	Application Layer:
		Contains applications - specific business rules.
		Encapsulates and implements all the use cases of the system.
	Interfaces Adapters Layer(Infrastructure Layer):
		Converts data from the format most convenient for the use cases and entities to the format most convenient for external systems.
	Frameworks and Drivers Layer (Infrastructure/External Concerns):
		The outermost layer consisting of frameworkd and tools such as the DB the Web Framework. etc
		General includes the UI, DB and external interfaces etc.




Design patterns and principles are essential concepts in software development that help create well-structured, maintainable, and scalable code. Here's an overview of some key design patterns and principles:
Design Patterns

Design patterns are typical solutions to common problems in software design. They can be categorized into three main types: creational, structural, and behavioral.
Creational Patterns

    Singleton: Ensures a class has only one instance and provides a global point of access to it.
    Factory Method: Defines an interface for creating an object but allows subclasses to alter the type of objects that will be created.
    Abstract Factory: Provides an interface for creating families of related or dependent objects without specifying their concrete classes.
    Builder: Separates the construction of a complex object from its representation so that the same construction process can create different representations.
    Prototype: Specifies the kinds of objects to create using a prototypical instance and creates new objects by copying this prototype.

Structural Patterns

    Adapter: Allows objects with incompatible interfaces to work together.
    Bridge: Separates an objects abstraction from its implementation so that both can vary independently.
    Composite: Composes objects into tree structures to represent part-whole hierarchies. It lets clients treat individual objects and compositions of objects uniformly.
    Decorator: Adds additional functionality to an object dynamically.
    Facade: Provides a simplified interface to a complex subsystem.
    Flyweight: Reduces the cost of creating and manipulating a large number of similar objects.
    Proxy: Provides a surrogate or placeholder for another object to control access to it.

Behavioral Patterns

    Chain of Responsibility: Passes a request along a chain of handlers. Upon receiving a request, each handler decides either to process the request or to pass it to the next handler in the chain.
    Command: Encapsulates a request as an object, thereby allowing for parameterization of clients with queues, requests, and operations.
    Interpreter: Defines a grammatical representation for a language and an interpreter to deal with this grammar.
    Iterator: Provides a way to access the elements of an aggregate object sequentially without exposing its underlying representation.
    Mediator: Defines an object that encapsulates how a set of objects interact.
    Memento: Provides the ability to restore an object to its previous state.
    Observer: Defines a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically.
    State: Allows an object to alter its behavior when its internal state changes. The object will appear to change its class.
    Strategy: Defines a family of algorithms, encapsulates each one, and makes them interchangeable.
    Template Method: Defines the skeleton of an algorithm in an operation, deferring some steps to subclasses.
    Visitor: Represents an operation to be performed on the elements of an object structure. It lets you define a new operation without changing the classes of the elements on which it operates.

Design Principles

Design principles are guidelines for writing clean, scalable, and maintainable code. The most well-known set of design principles is SOLID, which stands for:

    Single Responsibility Principle (SRP): A class should have one and only one reason to change, meaning it should only have one job or responsibility.
    Open/Closed Principle (OCP): Software entities should be open for extension but closed for modification.
    Liskov Substitution Principle (LSP): Objects of a superclass should be replaceable with objects of its subclasses without affecting the correctness of the program.
    Interface Segregation Principle (ISP): No client should be forced to depend on methods it does not use. This means many client-specific interfaces are better than one general-purpose interface.
    Dependency Inversion Principle (DIP): High-level modules should not depend on low-level modules. Both should depend on abstractions. Additionally, abstractions should not depend on details. Details should depend on abstractions.

    --------------------------------------------------------------------------------------------
    Tatical DDD:
    it is a set of patterns and principles that help in modeling complex software systems.
    Focuses on the domain and domain logic, importance of a model that reflects the business and its rules.
    Entities, Value Objects, Aggregates and Aggregate Root.

    Entities :
    It is an object that is identified by its identity(ID) rather than its attributes.
    Identity makes each entity unique, even if other attributes are the same.
    Entities are used to represent objects in the system that have a distinct identity and lifecycle.
    Example: Ordering microservices, an Order can be an Entity..
    It is uniquely identified by an OrderId, even if other attributes(like date, total amount) are identical to another  order.

    Value Objects:
    It is an object that describes some characteristics or attribute but carries no concept of identity.
    Value Objects are used to describe aspects of the domain with no conceptual identity.
    They are immutable and are often used to encapsulate complex attributes.
    Example: An Address used in an Order might be Value Object, as it is important for the order but does not define the order's identity.

    Aggregates:
    It is a cluster of domain objects(Entities and Value Object) that can be treated as a single unit.
    Aggregate will have one of its components be the Aggregate Root.
    Define a boundary around related objects.
    Operations within the boundary should maintain consiistency of changes to data in an Aggregate.
    Example: Order can be an Aggregate, containing OrderItems, PaymentDetails, etc. within it. The consistency of an order (like, total price calculation, stock validation) is maintained within the Aggregate boundaries.

    Aggregate Roots:
    Aggregate Root is the main Entity in an Aggrate, through which external objects interact with the Aggregate.
    Provides a gateway to the Aggregate, ensuring that the Aggregate's invariants are enforced and consistency is maintained.
    Example: In the order Aggregate, Order itselff can be the Aggregate Root. 
    External objects would interact with Order to affect changes within the Aggregate.

-------------------------------------------------------------
Primitive Obsession:
It is a code smell where primitives(like string, int, Guid) are used for domain concepts, leading to ambiguity and errors.
Using Guid or String for an orderID, CustomerId, or ProductId makes it easy to mix these identifiers up, as they're all of the same type.

Strongly Type Ids:
Creating distinct types for each kind of ID in your domain.
This makes your code more expressive and less error-prone.
It clarifies which type of ID is expected and prevents accidentally using one type of ID(like a productID) where another (like an orderID) is intended

-----------------------------------------------------------------------
Anemic Domain Model Entity:
Entity have little or no business logic(domain logic).
Essentially DS with getters and setters.
But the business rules and behaviors are typically implemented outside the entity, often in service layers.
Order class is anemic because it only contains data and lacks any domain logic or behaviors.
Business logic is scattered across the application, often in services.
Entities are simple data containers and easier to understand initially,
but it can lead to issues with maintainability and understanding the business logic by time.


Rich-Domain Model Entity
Entities encapsulate both data and behavior.
This model enriches entities with methods that embody business rules and domain logic.
Order is rich domain model as it includes methods AddOrderItems and RemoveOrderItem which encapsulate the business logic for manipulating the order items.
It encapsulates the business logic within the entities more closely, represent the real world business domain, and it can be more complex to design, but leads to a more maintainable and cohesive model.

----------------------------------------------
Domain Event in DDD:
Domain Events represent something that happended in the past and the other parts of the same service boundary same domain need to react to these changes.
Domain Event is a business event that occurs within the domain model.
Achieve consistency between aggregates in same domain
When an order is placed an OrderPlaced even might be triggered 
Trigger side effect or notify other parts of the system about changes within the domain

How to Use Domain Events in DDD?
Encapsulate the event details and dispatch them to interested parties.

Domain vs Integrations Events

Domain
Published and consumed within a single domain.
Strictly within the boundary of the microservice/domain context.
Indicate something that has happened within the aggregat.
In-process and synchronously, send using an in-memory message bus

Integration Events:
Used to communicate state changes or events between contexts or microservices.
Overall System's reaction to certain domain events
Asynchronously, sent with a message broker over a queue
Example After handling orderplaced event an OrderPlacedIntegrationEvent might be published to a message broker like RabbitMQ, then consumes by other Microservices.

------------------------------------------------------------------------

EF core Interceptors: SaveChangesInterceeptor for Auditing Entites
    Interceptors in EF Core enable the interception, modification, or
    suppression of EF Core operations
    This includes low-level database operations such as executing a command
    as well as higher-level operations, suct as calls to SaveChanges.
SaveChanges Interception:
    The SaveChanges and SaveChangesAsync interception point are used to execute custom
    logic when saving changes to the database.
    These interception points are defined by the ISaveChangesInterceptior interfaces.
    EF Core provides a SaveChangesInterceptor base class with no-op(no operation) methods as a convenience

Use Case: SaveChanges interception for Auditing
    Interception of SaveChanges can be used to create an independent audit record of changes.
    This is useful for maintaining a history of who changed an entity and when.
    Before saving changes to the database, you can iterate through the changd entities in the DBContext and log or store the 

Registering Interceptors
    How to Register Interceptors?
    Interceptors are registered using AddInterceptors when Congfiguring a DbContext instance.
    Common approach is usually done in the OnConfiguring method of the DbContext.
    Example Code: Registering a SaveChangesInterceptor.

Implementing a Custome SaveChangesInterceptor:
    Implement a custom interceptor by extending SaveChangesInterceptor or implementing ISaveChangesInterceptor.
    Override methods like SavingChanges and SavedChanges to execute custom logic.
    

-------------------------------------------------------------------

CQRS:
It is design pattern in order to avoid complex queries to get rid of inefficient joins.
Separates read and write operations with separating database.
Commands: Changing the state of data into application.
Queries: Handlling complex join operations and returning a result and dont change the state of data into application.
Large-scaled microservices architectures needs to manage high-volume data requirements.
Single database for services can cause bottlenecks.
Uses both CQRS and Event Sourcing patterns to improve application performance.
CQRS offers to separates read and write data that provides to maximize query performance and scalability.


Monolithic has single db is both working for complex join queries, and also perform CRUD operations.
When application goes more complex, this query and CRUD operations will become un-manageable situation.
Application required some query that needs to join more than 10 table, will lock the DB due to latency of query computation.
Performing CRUD operations need to make complex validations and process long business logics, will cause to lock db operations.
Reading and writing dn has different approaches define different strategy.
Separation of concerns principles: separate reading db and writing db with 2 db.
    Read db uses No-Sql db with denirmalized data
    Write db uses relational db with fully normalized and support strong data consistency.


    Event Sourcing Pattern :
    Most applications save data into db with the current state of the entity. i.e user changes the email address table, email field updated with the latest updated one. Always know the lastest status of the data.
    In large-scaled architectures, frequent update database operations can negatively impact datbase performance, responsiveness, and limits of scalability.
    Event Sourcing pattern offers to persist each action that affects to data into Event Store database. And call all these action as a event.
    Instead of saving latest status of data into database, event sourcing pattern offers to save all events into db with sequential ordered of data events.
    This events database called Event Store.
    Instead of overriding the data into table, it create a new record for each change to data and it becomes sequential list of past events.
    Event Store database become the source of truth of data.
    Sequential Event list using for generating Materialized Views that represents final state of data to perform queries.
    Event store convert to read db with following the Materialized View Pattern.
    Convert operation can handle by publish/Subscribe pattern with publish event with message broker systems.
    Event list gives ability to replay events at given certain timestamp.

    CQRS pattern is mostly using with the Event Sourcing pattern.
    Store events into the write db source-of-truth events db.
    Read db of CQRS pattern provides materialized views of the data with denormalized tables.
    Materialized views read db consumes events from write db convert them into denormalized views.
    The writing db is never save status of data only events actions are stored.
    Store history of data and able to reply any point of time in order to re=generate status of data.
    System can increased query performance and scale db independently.



